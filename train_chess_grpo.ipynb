{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2645f5",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821b7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install -q \"torch==2.5.1\" --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install -q \"transformers==4.48.1\" \"datasets==3.1.0\" \"accelerate==1.3.0\" \"trl==0.14.0\"\n",
    "# !pip install -q \"peft==0.14.0\" \"bitsandbytes==0.45.0\" \"python-chess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fed150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "\n",
    "# Login to Hugging Face\n",
    "# login(token=\"\", add_to_git_credential=True)  # ADD YOUR TOKEN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98219a",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Chess Puzzle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2f01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2248 chess puzzle positions\n",
      "\n",
      "Sample puzzle:\n",
      "{\n",
      "  \"input\": {\n",
      "    \"fen\": \"r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - - 0 24\",\n",
      "    \"legal_moves\": [\n",
      "      \"a8g8\",\n",
      "      \"a8f8\",\n",
      "      \"a8e8\",\n",
      "      \"a8d8\",\n",
      "      \"a8c8\",\n",
      "      \"a8b8\",\n",
      "      \"e7e8\",\n",
      "      \"e7g7\",\n",
      "      \"e7f7\",\n",
      "      \"e7d7\",\n",
      "      \"e7c7\",\n",
      "      \"e7e6\",\n",
      "      \"f2b6\",\n",
      "      \"f2c5\",\n",
      "      \"f2d4\",\n",
      "      \"f2g3\",\n",
      "      \"f2e3\",\n",
      "      \"f2g1\",\n",
      "      \"f2e1\",\n",
      "      \"b2e5\",\n",
      "      \"b2d4\",\n",
      "      \"b2c3\",\n",
      "      \"b2b3\",\n",
      "      \"b2a3\",\n",
      "      \"b2c2\",\n",
      "      \"b2a2\",\n",
      "      \"b2c1\",\n",
      "      \"b2b1\",\n",
      "      \"b2a1\",\n",
      "      \"b7b6\",\n",
      "      \"a7a6\",\n",
      "      \"f6f5\",\n",
      "      \"d5d4\",\n",
      "      \"b7b5\",\n",
      "      \"a7a5\"\n",
      "    ],\n",
      "    \"side_to_move\": \"Black\"\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"move\": \"f2g3\",\n",
      "    \"solution\": [\n",
      "      \"f2g3\",\n",
      "      \"e6e7\",\n",
      "      \"b2b1\",\n",
      "      \"b3c1\",\n",
      "      \"b1c1\",\n",
      "      \"h6c1\"\n",
      "    ]\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"puzzle_id\": \"00008\",\n",
      "    \"rating\": 1877,\n",
      "    \"themes\": [\n",
      "      \"crushing\",\n",
      "      \"hangingPiece\",\n",
      "      \"long\",\n",
      "      \"middlegame\"\n",
      "    ],\n",
      "    \"game_url\": \"https://lichess.org/787zsVup/black#48\",\n",
      "    \"opening_tags\": [],\n",
      "    \"move_number\": 1,\n",
      "    \"total_moves\": 6\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"unsloth/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# Load your extracted puzzles\n",
    "puzzle_file = \"data/processed/chess_puzzles_2248.jsonl\"\n",
    "\n",
    "puzzles = []\n",
    "with open(puzzle_file, 'r') as f:\n",
    "    for line in f:\n",
    "        puzzles.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(puzzles)} chess puzzle positions\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Sample puzzle\n",
    "print(\"\\nSample puzzle:\")\n",
    "print(json.dumps(puzzles[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdcdd87",
   "metadata": {},
   "source": [
    "## 3. Create Prompt Format for Chess\n",
    "\n",
    "We'll use the same format as your prompt.py: `<rationale>` and `<uci_move>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c3c5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample prompt:\n",
      "<|im_start|>system\n",
      "You are a chess expert. Analyze positions carefully and find the best tactical move.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this chess position and find the BEST move.\n",
      "\n",
      "Position (FEN): r6k/pp2r2p/4Rp1Q/3p4/8/1N1P2R1/PqP2bPP/7K b - - 0 24\n",
      "Side to move: Black\n",
      "Legal moves: a8g8 a8f8 a8e8 a8d8 a8c8 a8b8 e7e8 e7g7 e7f7 e7d7 e7c7 e7e6 f2b6 f2c5 f2d4 f2g3 f2e3 f2g1 f2e1 b2e5 b2d4 b2c3 b2b3 b2a3 b2c2 b2a2 b2c1 b2b1 b2a1 b7b6 a7a6 f6f5 d5d4 b7b5 a7a5\n",
      "\n",
      "Explain your reasoning in <rationale> tags, then provide the move in <uci_move> tags.\n",
      "Example: <rationale>Fork attacking king and queen</rationale><uci_move>f2g3</uci_move><|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Let me analyze this position.\n",
      "<rationale>\n",
      "\n",
      "Correct move: f2g3\n"
     ]
    }
   ],
   "source": [
    "def format_chess_prompt(puzzle_data):\n",
    "    \"\"\"\n",
    "    Format a chess puzzle into GRPO training format.\n",
    "    Includes a thinking prefix to encourage reasoning.\n",
    "    \"\"\"\n",
    "    inp = puzzle_data['input']\n",
    "    \n",
    "    # System message\n",
    "    system_msg = \"You are a chess expert. Analyze positions carefully and find the best tactical move.\"\n",
    "    \n",
    "    # User prompt\n",
    "    user_msg = f\"\"\"Analyze this chess position and find the BEST move.\n",
    "\n",
    "Position (FEN): {inp['fen']}\n",
    "Side to move: {inp['side_to_move']}\n",
    "Legal moves: {' '.join(inp['legal_moves'])}\n",
    "\n",
    "Explain your reasoning in <rationale> tags, then provide the move in <uci_move> tags.\n",
    "Example: <rationale>Fork attacking king and queen</rationale><uci_move>f2g3</uci_move>\"\"\"\n",
    "    \n",
    "    # Prefill assistant to start reasoning\n",
    "    assistant_prefix = \"Let me analyze this position.\\n<rationale>\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_prefix}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            continue_final_message=True\n",
    "        ),\n",
    "        \"correct_move\": puzzle_data['output']['move'],\n",
    "        \"legal_moves\": inp['legal_moves'],\n",
    "        \"puzzle_id\": puzzle_data['metadata']['puzzle_id'],\n",
    "        \"rating\": puzzle_data['metadata']['rating']\n",
    "    }\n",
    "\n",
    "# Test the formatting\n",
    "sample = format_chess_prompt(puzzles[0])\n",
    "print(\"Sample prompt:\")\n",
    "print(sample['prompt'])\n",
    "print(f\"\\nCorrect move: {sample['correct_move']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481e1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2023 | Test: 225\n"
     ]
    }
   ],
   "source": [
    "# Convert all puzzles to GRPO format\n",
    "formatted_puzzles = [format_chess_prompt(p) for p in puzzles]\n",
    "\n",
    "# Create Hugging Face dataset\n",
    "dataset = Dataset.from_list(formatted_puzzles)\n",
    "\n",
    "# Split train/test\n",
    "train_test_split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f7069",
   "metadata": {},
   "source": [
    "## 4. Define Reward Functions\n",
    "\n",
    "We'll create 3 reward functions:\n",
    "1. **Format Reward**: Correct XML tags `<rationale>...</rationale><uci_move>...</uci_move>`\n",
    "2. **Legality Reward**: Move is in the legal moves list\n",
    "3. **Correctness Reward**: Move matches the puzzle solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22288a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_reward_func(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward for correct format: <rationale>...</rationale><uci_move>...</uci_move>\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for completion in completions:\n",
    "        try:\n",
    "            # Add synthetic <rationale> since it's prefilled\n",
    "            text = \"<rationale>\" + completion\n",
    "            \n",
    "            # Check format\n",
    "            regex = r\"<rationale>([^<]*(?:<(?!/?rationale>)[^<]*)*)</rationale>\\s*<uci_move>([^<]+)</uci_move>\"\n",
    "            match = re.search(regex, text, re.DOTALL)\n",
    "            \n",
    "            if match and len(match.groups()) == 2:\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        except:\n",
    "            rewards.append(0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def legality_reward_func(completions, legal_moves, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward if the move is legal.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for completion, legal in zip(completions, legal_moves):\n",
    "        try:\n",
    "            text = \"<rationale>\" + completion\n",
    "            \n",
    "            # Extract move\n",
    "            match = re.search(r\"<uci_move>([^<]+)</uci_move>\", text)\n",
    "            if not match:\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            move = match.group(1).strip()\n",
    "            \n",
    "            # Check if legal\n",
    "            if move in legal:\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(-1.0)  # Penalize illegal moves\n",
    "        except:\n",
    "            rewards.append(0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def correctness_reward_func(completions, correct_move, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward if the move is correct (matches puzzle solution).\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for completion, correct in zip(completions, correct_move):\n",
    "        try:\n",
    "            text = \"<rationale>\" + completion\n",
    "            \n",
    "            # Extract move\n",
    "            match = re.search(r\"<uci_move>([^<]+)</uci_move>\", text)\n",
    "            if not match:\n",
    "                rewards.append(-0.5)\n",
    "                continue\n",
    "            \n",
    "            move = match.group(1).strip()\n",
    "            \n",
    "            # Check correctness\n",
    "            if move == correct:\n",
    "                rewards.append(3.0)  # High reward for correct solution\n",
    "            else:\n",
    "                rewards.append(-0.5)  # Small penalty for wrong move\n",
    "        except:\n",
    "            rewards.append(-0.5)\n",
    "    \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca068d50",
   "metadata": {},
   "source": [
    "### Test Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1185427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format rewards: [1.0, 0.0, 1.0]\n",
      "Legality rewards: [1.0, 0.0, -1.0]\n",
      "Correctness rewards: [3.0, -0.5, -0.5]\n"
     ]
    }
   ],
   "source": [
    "# Test samples\n",
    "correct_sample = \"\"\"I see that the bishop on f2 can capture the rook on g3, winning material.</rationale>\n",
    "<uci_move>f2g3</uci_move>\"\"\"\n",
    "\n",
    "wrong_format = \"\"\"The best move is f2g3 because it wins the rook.\"\"\"\n",
    "\n",
    "illegal_move = \"\"\"Moving the pawn forward.</rationale>\n",
    "<uci_move>z9z9</uci_move>\"\"\"\n",
    "\n",
    "# Test\n",
    "test_completions = [correct_sample, wrong_format, illegal_move]\n",
    "test_legal_moves = [[\"f2g3\", \"a8g8\", \"e7e8\"]] * 3\n",
    "test_correct = [\"f2g3\"] * 3\n",
    "\n",
    "print(\"Format rewards:\", format_reward_func(test_completions))\n",
    "print(\"Legality rewards:\", legality_reward_func(test_completions, legal_moves=test_legal_moves))\n",
    "print(\"Correctness rewards:\", correctness_reward_func(test_completions, correct_move=test_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc441cf4",
   "metadata": {},
   "source": [
    "## 5. Setup GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89def04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:24: FutureWarning: `torch_dtype` is deprecated and will be removed in version 0.27.0, please use `dtype` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:192: FutureWarning: The `max_prompt_length` argument is deprecated and will be removed in version 0.28.0. You should instead filter your dataset before training to ensure that prompts do not exceed your desired length.\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer, ModelConfig, get_peft_config\n",
    "\n",
    "# Model config\n",
    "model_config = ModelConfig(\n",
    "    model_name_or_path=model_name,\n",
    "    dtype=\"bfloat16\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    use_peft=True,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# GRPO Training config\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"chess-grpo-qwen3\",\n",
    "    learning_rate=5e-7,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10,\n",
    "    max_steps=200,  # Start small for testing\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    bf16=True,\n",
    "    \n",
    "    # GRPO specific\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=256,\n",
    "    num_generations=2,  # Generate 2 solutions per puzzle\n",
    "    beta=0.001,  # KL coefficient\n",
    "    \n",
    "    # Logging\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "print(\"Config ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4889ae",
   "metadata": {},
   "source": [
    "## 6. Create Trainer and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b87c73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db07cce8be9e4feb8eacfad229d54fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-26 16:27:59] INFO spawn.py:77: gcc -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -fPIC -c /tmp/tmp3wsv0mi2/test.c -o /tmp/tmp3wsv0mi2/test.o\n",
      "[2025-12-26 16:27:59] INFO spawn.py:77: gcc /tmp/tmp3wsv0mi2/test.o -laio -o /tmp/tmp3wsv0mi2/a.out\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "[2025-12-26 16:27:59] INFO spawn.py:77: gcc -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -fPIC -c /tmp/tmphynfpoel/test.c -o /tmp/tmphynfpoel/test.o\n",
      "[2025-12-26 16:27:59] INFO spawn.py:77: gcc /tmp/tmphynfpoel/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmphynfpoel/a.out\n",
      "/usr/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer created successfully!\n"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model_config.model_name_or_path,\n",
    "    reward_funcs=[\n",
    "        format_reward_func,\n",
    "        legality_reward_func,\n",
    "        correctness_reward_func\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=get_peft_config(model_config),\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 40960}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 37:16, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>-0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>-0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>-0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>-0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>-0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>-0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>-0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>-0.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>-0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>-0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>-0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>-0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to chess-grpo-qwen3-8b\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "# trainer.save_model(training_args.output_dir)\n",
    "print(f\"Model saved to {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abddfe",
   "metadata": {},
   "source": [
    "## 7. Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ded811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99791bbfea1496ea95169a4d476425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Puzzle 1 (Rating: 1877)\n",
      "Correct move: f2g3\n",
      "================================================================================\n",
      "Black has a strong queen on h5 and a rook on g8. The key is to find a move that maximizes pressure. The move e7e6 opens up the e-file and supports the rook on g8. It also prepares to develop the bishop on c8. This move is both tactical and strategic, improving piece activity and controlling key squares.</rationale>\n",
      "<uci_move>e7e6</uci_move>\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Puzzle 2 (Rating: 1877)\n",
      "Correct move: b2b1\n",
      "================================================================================\n",
      "Black's king is in a dangerous position with limited mobility. The most promising move is to play b7b5, which opens up the diagonal for the knight and prepares to develop the queen. This move also threatens to create a fork with the queen and knight.</rationale>\n",
      "<uci_move>b7b5</uci_move>\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Puzzle 3 (Rating: 1877)\n",
      "Correct move: b1c1\n",
      "================================================================================\n",
      "Black has a strong attacking position with the queen and rook on the queenside. The key is to find a move that maximizes pressure and creates threats. The move g3h4 is a strong candidate as it threatens to deliver checkmate on h5 or h6. It also attacks the white queen on h8 and creates a fork with the rook on a8. This move is both tactical and strategic, as it opens lines for the rook and prepares for further attacks.</rationale>\n",
      "<uci_move>g3h4</uci_move>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on a few puzzles\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    training_args.output_dir,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Test on 3 puzzles\n",
    "for i in range(3):\n",
    "    puzzle = puzzles[i]\n",
    "    prompt = format_chess_prompt(puzzle)['prompt']\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.7,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Puzzle {i+1} (Rating: {puzzle['metadata']['rating']})\")\n",
    "    print(f\"Correct move: {puzzle['output']['move']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(response)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-chess-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
